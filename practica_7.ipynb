{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1983b96d-d20c-4d13-b6f0-61997eff7e50",
   "metadata": {},
   "source": [
    "# 游빍 Practica 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44700c26-1270-415f-84a7-19b0bf17fa08",
   "metadata": {},
   "source": [
    "# Tipos de prompting 游빌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed849a2d-9d5c-4175-a657-79defbc049e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai --break-system-package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985cc55-e7c1-4819-95b9-bc67dc30592b",
   "metadata": {},
   "source": [
    "# T칠cnica #1 游꿢Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da4c1fb-13ec-45ba-b2ce-dcf22334f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Machine Learning es cuando ense침as a una computadora a aprender de ejemplos, en vez de programar cada acci칩n.\\n\\nImagina que le muestras a un ni침o muchas fotos de gatos.\\n\\nEventualmente, podr치 identificar un gato nuevo sin que se lo digas espec칤ficamente.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Inicializa el cliente de OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyDjSbFVf25PmVRHiuqhF7Bd8mI5VaVaOI0\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Prompt zero-shot: Instruye al modelo sin ejemplos\n",
    "prompt = \"\"\"\n",
    "Soy un estudiante de ingenier칤a sin experiencia en IA. Explica qu칠 es machine learning en m치ximo 3 l칤neas, incluyendo 1 analog칤a simple. Evita t칠rminos t칠cnicos complejos.\n",
    "\"\"\"\n",
    "\n",
    "# Env칤a la solicitud al modelo\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2574a68c-d8b0-46f8-a4da-694832d98d75",
   "metadata": {},
   "source": [
    "# 游닄 T칠cnica #2 游닄One-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0de807a-0010-4ef6-9b89-4bf94959abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Problema: La plataforma de e-commerce presentaba problemas de escalabilidad, afectando su rendimiento y disponibilidad.\\nSoluci칩n: Se implement칩 una migraci칩n a Kubernetes, adoptando contenedores Docker y capacidades de auto-scaling. Se utiliz칩 Helm para gestionar los despliegues y Prometheus para el monitoreo.\\nImpacto: Se logr칩 reducir el downtime del 15% al 2% y mejorar el throughput en un 40%.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Inicializa el cliente de OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyDjSbFVf25PmVRHiuqhF7Bd8mI5VaVaOI0\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Prompt zero-shot: Instruye al modelo sin ejemplos\n",
    "prompt = \"\"\"\n",
    "Soy gerente de proyectos. Necesito resumir reportes t칠cnicos r치pidamente para reuniones ejecutivas.\n",
    "\n",
    "Aqu칤 va un EJEMPLO del formato que quiero:\n",
    "\n",
    "EJEMPLO:\n",
    "Problema: La infraestructura antigua causa latencia en consultas de BD\n",
    "Soluci칩n: Implementar cach칠 distribuido con Redis\n",
    "Impacto: Reducci칩n de 80% en latencia, ahorro de 30% en servidores\n",
    "\n",
    "Ahora, resume el siguiente art칤culo usando el mismo formato exacto:\n",
    "[ART칈CULO A RESUMIR: \"El art칤culo discute c칩mo la migraci칩n a Kubernetes resolvi칩 problemas de escalabilidad en una plataforma de e-commerce. La implementaci칩n incluy칩 contenedores Docker y auto-scaling, reduciendo downtime del 15% al 2% y mejorando el throughput en 40%. Se us칩 Helm para deployments y Prometheus para monitoreo.\"]\n",
    "\n",
    "Restricciones: Tono profesional, m치ximo 150 palabras totales, enf칩cate solo en problema, soluci칩n e impacto.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Env칤a la solicitud al modelo\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017f721-6788-4c7c-b0fd-a3aea0bb0535",
   "metadata": {},
   "source": [
    "# 游꿉 T칠cnica #3 - Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafcc204-dcbd-4488-9d14-57f0f0e7a4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='```json\\n{\\n  \"severidad\": \"P2\",\\n  \"categor칤a\": \"Backend\",\\n  \"acci칩n\": \"Optimizar consultas\"\\n}\\n```', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Inicializa el cliente de OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyDjSbFVf25PmVRHiuqhF7Bd8mI5VaVaOI0\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Prompt zero-shot: Instruye al modelo sin ejemplos\n",
    "prompt = \"\"\"\n",
    "Eres un clasificador de bugs especializado en desarrollo de software. Clasifica bugs siguiendo exactamente el patr칩n de los ejemplos proporcionados, enfoc치ndote en severidad (P1: Cr칤tica, P2: Alta, P3: Media, P4: Baja), categor칤a t칠cnica y acci칩n inmediata recomendada.\n",
    "\n",
    "Aqu칤 van 2 ejemplos:\n",
    "\n",
    "EJEMPLO 1:\n",
    "Input: \"Login no funciona\"\n",
    "Output: {severidad: \"P1\", categor칤a: \"Auth\", acci칩n: \"Revisar API\"}\n",
    "\n",
    "EJEMPLO 2:\n",
    "Input: \"Tipograf칤a rara en Safari\"\n",
    "Output: {severidad: \"P3\", categor칤a: \"UI\", acci칩n: \"Revisar CSS\"}\n",
    "\n",
    "Ahora clasifica este bug siguiendo el mismo patr칩n exacto:\n",
    "Input: \"Reportes tardan 60 segundos en cargar\"\n",
    "Output:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Env칤a la solicitud al modelo\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60cc24-5db3-4640-ba00-58137486aade",
   "metadata": {},
   "source": [
    "# 游 T칠cnica #4 - Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d6754e-4590-468d-a2c0-e63d8ce81887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1: Analiza s칤ntomas y datos disponibles\n",
      "El s칤ntoma principal es que las queries de PostgreSQL tardan 30s (normalmente <1s). Otros datos clave son: tr치fico normal (50k concurrentes), CPU, RAM e I/O de disco de los servidores de aplicaci칩n tambi칠n normales. Los logs muestran picos en tiempo de respuesta de BD sin errores obvios. Esto indica que el problema no reside en la infraestructura de las aplicaciones ni en una sobrecarga de tr치fico, sino directamente en la base de datos PostgreSQL.\n",
      "\n",
      "Paso 2: Descarta causas comunes basadas en los datos\n",
      "Descartamos:\n",
      "*   **Sobrecarga de servidores de aplicaci칩n:** CPU, RAM, I/O normales (25%, 40%, 5MB/s respectivamente).\n",
      "*   **Pico de tr치fico inusual:** 50k usuarios es el pico normal.\n",
      "*   **Problemas de red entre app y BD:** Si fuera as칤, ver칤amos errores de conexi칩n o timeouts m치s que solo queries lentas *tras* conectar.\n",
      "*   **Falta de recursos f칤sicos en el *servidor de base de datos* (CPU, RAM, I/O del disco):** Aunque no tenemos m칠tricas directas del servidor de BD, la causa m치s com칰n para queries lentas a carga normal es la ineficiencia, no necesariamente falta de recursos si las queries se ejecutan mal.\n",
      "\n",
      "Paso 3: Identifica causa probable con justificaci칩n\n",
      "La causa m치s probable es **ineficiencia en las queries SQL y/o la falta de 칤ndices adecuados** en la base de datos PostgreSQL.\n",
      "\n",
      "**Justificaci칩n:** Si los recursos de aplicaci칩n est치n bien y el tr치fico es el esperado, el cuello de botella est치 en c칩mo la BD procesa las peticiones. Queries que pasan de <1s a 30s a una carga normal suelen deberse a planes de ejecuci칩n ineficientes. Esto ocurre cuando los datos crecen, y queries previamente r치pidas empiezan a realizar escaneos completos de tablas (full table scans) o uniones (joins) ineficientes, consumiendo muchos m치s recursos internos del motor de BD.\n",
      "\n",
      "Paso 4: Prop칩n 3 soluciones inmediatas con pasos de implementaci칩n\n",
      "1.  **Identificar y optimizar queries lentas:**\n",
      "    *   **Pasos:** Activar `pg_stat_statements` (si no est치 activo). Consultar `pg_stat_statements` para listar las queries con mayor `total_time` o `mean_time`. Usar `EXPLAIN ANALYZE` en las queries identificadas para entender su plan de ejecuci칩n y los cuellos de botella.\n",
      "2.  **Revisar y a침adir 칤ndices:**\n",
      "    *   **Pasos:** Basado en el `EXPLAIN ANALYZE`, crear 칤ndices `B-tree` en columnas usadas en cl치usulas `WHERE`, `JOIN` y `ORDER BY` que no los tengan, o donde el 칤ndice existente no sea 칩ptimo. Priorizar columnas con alta cardinalidad.\n",
      "3.  **Ajustar configuraci칩n de PostgreSQL:**\n",
      "    *   **Pasos:** Revisar `postgresql.conf`. Ajustar `work_mem` (si hay joins/sorts grandes que se desbordan a disco) y `shared_buffers` (cache de datos). Un `work_mem` bajo es una causa com칰n de lentitud en operaciones de ordenamiento.\n",
      "\n",
      "Diagn칩stico Final\n",
      "La causa principal de la ralentizaci칩n de la BD es la **ineficiencia de las queries SQL y/o la ausencia de 칤ndices 칩ptimos**. Al optimizar las queries m치s costosas y a침adir los 칤ndices necesarios, esperamos que el tiempo de respuesta de las consultas vuelva a niveles normales (<1s), restaurando la performance de la aplicaci칩n web.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Inicializa el cliente de OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=\"AIzaSyDjSbFVf25PmVRHiuqhF7Bd8mI5VaVaOI0\",\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Prompt zero-shot: Instruye al modelo sin ejemplos\n",
    "prompt = \"\"\"\n",
    "Soy SRE (Site Reliability Engineer) con 3 a침os de experiencia en infraestructura cloud. Tengo un problema de performance en mi aplicaci칩n web:\n",
    "\n",
    "Datos de monitoreo:\n",
    "- Base de datos PostgreSQL lenta (queries tardan 30s, normalmente <1s)\n",
    "- CPU en servidores: 25% (normal)\n",
    "- Memoria RAM: 40% (normal)\n",
    "- I/O del disco: Normal (5MB/s)\n",
    "- Tr치fico: 50k usuarios concurrentes (pico normal)\n",
    "- Logs: No hay errores obvios, pero spikes en tiempo de respuesta de BD\n",
    "\n",
    "Diagnostica qu칠 est치 pasando. Razona paso a paso mostrando tu l칩gica t칠cnica, luego da el diagn칩stico final.\n",
    "\n",
    "Estructura obligatoria:\n",
    "Paso 1: [Analiza s칤ntomas y datos disponibles]\n",
    "Paso 2: [Descarta causas comunes basadas en los datos]\n",
    "Paso 3: [Identifica causa probable con justificaci칩n]\n",
    "Paso 4: [Prop칩n 3 soluciones inmediatas con pasos de implementaci칩n]\n",
    "Diagn칩stico Final: [Conclusi칩n clara con impacto esperado]\n",
    "\n",
    "Restricciones: Enf칩cate en soluciones pr치cticas para PostgreSQL, m치ximo 300 palabras, usa lenguaje t칠cnico pero accesible para un equipo junior.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Env칤a la solicitud al modelo\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Imprime la respuesta\n",
    "print(response.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a43d72-0dc3-42c4-a2a7-102488e5c588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
