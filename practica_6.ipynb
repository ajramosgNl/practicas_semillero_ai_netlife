{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHIkU-p8KT90"
   },
   "source": [
    "## И Practica 6\n",
    "\n",
    "###  Interactuando con Ollama y Modelos Locales "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZsCzSdvKf8L"
   },
   "source": [
    "### 1. Conectar OLLAMA al SDK Oficial\n",
    "Una vez instalado Ollama en tu m谩quina. Descarga el modelo `gemma3:270m-it-fp16` ejecutando el comando `ollama run gemma3:270m-it-fp16`. Ejecuta el siguiente c贸digo para ejecutar ejemplos de prompts con zero shot, one shot, few shot y chain of thought para resolver un problema recurrente en tareas de tu carrera. Por ejemplo: Redactar un informe, obtener informaci贸n sobre un tema. Mide los tiempos de ejecuci贸n de cada prompt y documenta la calidad de sus respuestas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suZOQcwVKJFo"
   },
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='gemma3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Redactame lo acontecido en la guerra del cenepa en 2 parrafos',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJGYdNcQLqz3"
   },
   "source": [
    "### 2. Conectar OLLAMA al SDK de OpenAI\n",
    "\n",
    "Una vez instalado Ollama en tu m谩quina. Descarga el modelo `gemma3:270m-it-fp16` ejecutando el comando `ollama run gemma3:270m-it-fp16`. Ejecuta el siguiente c贸digo para ejecutar ejemplos de prompts con zero shot, one shot, few shot y chain of thought para resolver un problema recurrente en tareas de tu carrera. Por ejemplo: Redactar un informe, obtener informaci贸n sobre un tema. Mide los tiempos de ejecuci贸n de cada prompt y documenta la calidad de sus respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8E2HYuuTLvTn"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gemma3:270m-it-fp16\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkpUgdDBNNgT"
   },
   "source": [
    "### Responder: 驴Que diferencias encuentras al usar el SDK de ollama vs OpenAI\n",
    "\n",
    "-- Tu respuesta aqu铆 --"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
